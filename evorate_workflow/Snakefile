import glob

configfile: "config/wmel_config2.yaml"

samples = []
with open(config["accession_list"], 'r') as file:
    for line in file:
        samples.append(line.strip())
work_dir = config["work_dir"]
log_file=config["log_path"]

rule all:
    input:
        expand("{work_dir}/results/{sample}_absrel.json", work_dir=config["work_dir"], sample=samples)
        
checkpoint download_genomes:
    input:
        query_proteome=config["query_proteome"]
    params:
        microbe_id=config["microbe_id"],
        taxon_id=config["taxon_id"],
        taxon_ids=",".join(map(str, config["taxon_ids"])),
        free_living_taxon_ids=",".join(map(str, config["free_living_taxon_ids"])), 
        work_dir=config["work_dir"],
        max_genomes=config["max_genomes"],
        log_file=config["log_path"],
        nltk_data_dir=config["nltk_data_dir"], 
        globi_db_path=config["globi_db_path"]
    output:
        genomes=directory("{work_dir}/genomes"), 
        marker=touch("{work_dir}/genomes/.done")
    shell:
        """
        python scripts/download_genomes_multi.py \
            -p {input.query_proteome} \
            -i {params.microbe_id} \
            -x {params.taxon_ids} \
            -w {params.work_dir} \
            -m {params.max_genomes} \
            -l {params.log_file} \
            -f {params.free_living_taxon_ids} \
            -n {params.nltk_data_dir} \
            -g {params.globi_db_path}
        """
    
def wait_for_genomes(wc): 
    from pathlib import Path
    checkpoint_output = checkpoints.download_genomes.get(**wc).output[0]
    genomes = [f.stem for f in Path(checkpoint_output).glob("*.zip")]
    return expand("{work_dir}/rbh_results/{genome}_filtered.tsv", work_dir=wc.work_dir, genome=genomes)
        
rule mmseq_rbh:
    input:
        genomes="{work_dir}/genomes/{genome}.zip",#lambda wildcards: glob.glob("{work_dir}/genomes/*".format(work_dir=config["work_dir"])),
        marker="{work_dir}/genomes/.done"
    params:
        query_proteome=config["query_proteome"],
        threads=config["mmseq_threads"],
        microbe_id=config["microbe_id"],
        taxon_id=config["taxon_id"],
        work_dir=config["work_dir"],
        max_genomes=config["max_genomes"],
        log_file=lambda wildcards: config["log_path"],
        genome_ids=lambda wildcards: "{}genomes_selected.txt".format(config["log_path"])
    output:
        "{work_dir}/rbh_results/{genome}_filtered.tsv" 
    shell:
        """
        python scripts/mmseq_rbh.py \
            -p {params.query_proteome} \
            -t {params.threads} \
            -i {params.microbe_id} \
            -s {params.genome_ids} \
            -w {params.work_dir} \
            -l {params.log_file} \
            -g {input.genomes}
        """

rule collect_mmseq:
    input:
        wait_for_genomes
    output:
        touch("{work_dir}/rbh_results/.done")

def wait_for_genes(wc):
    from pathlib import Path
    checkpoint_output = checkpoints.collect_orthologs.get(**wc).output[0]
    genes = [f.parent.name for f in Path(checkpoint_output).rglob("*.fna")]
    return expand("{work_dir}/msa_files/{sample}/{sample}.fna", work_dir=wc.work_dir, sample=genes)

checkpoint collect_orthologs:
    input:
        rules.collect_mmseq.output,
    params:
        microbe_id=config["microbe_id"],
        work_dir=config["work_dir"],
        log_file=config["log_path"],
        candidates=config["accession_list"],
        max_ortho_seqs=config["max_ortho_seqs"]
    output:
        ortholog_fastas=expand("{{work_dir}}/msa_files/{sample}/{sample}.fna", sample=samples),
        marker=touch("{work_dir}/msa_files/.done")
    shell:
        """
        python scripts/collect_orthologs.py \
            -i {params.microbe_id} \
            -c {params.candidates} \
            -w {params.work_dir} \
            -j {params.work_dir}/genomes/genome_accession_map.json \
            -l {params.log_file} \
            -m {params.max_ortho_seqs} 
        """

rule collect_gene_datasets:
    input:
        wait_for_genes
    output:
        touch("{work_dir}/.ortholog_collection_done")

rule format_seq_names:
    input:
        "{work_dir}/msa_files/{sample}/{sample}.fna"
    output:
        "{work_dir}/msa_files/{sample}/{sample}.renamed.fna"
    shell:
        '''
        sed -e 's/:/_/g' -e 's/\./_/g' -e 's/\[/_/g' -e 's/\]/_/g' -e 's/\=/_/g' {input} > {output}
        '''

rule macse_hmmcleaner:
    input:
        "{work_dir}/msa_files/{sample}/{sample}.renamed.fna"
    output:
        "{work_dir}/msa_files/{sample}/{sample}_final_align_NT.aln"
    shell:
        '''
        bash scripts/MACSE_HMMCleaner.sh --in_seq_file {input} --out_dir "{work_dir}/msa_files/{wildcards.sample}" --out_file_prefix {wildcards.sample} --genetic_code_number 11
        '''

rule iqtree:
    input:
        "{work_dir}/msa_files/{sample}/{sample}_final_align_NT.aln"
    output:
        "{work_dir}/tree_files/{sample}/{sample}.treefile"
    shell:
        '''
        iqtree -s {input} --prefix "{work_dir}/tree_files/{wildcards.sample}/{wildcards.sample}" -nt AUTO --quiet
        '''     

rule absrel:
    input:
        alignment="{work_dir}/msa_files/{sample}/{sample}_final_align_NT.aln",
        tree="{work_dir}/tree_files/{sample}/{sample}.treefile"
    output:
        "{work_dir}/results/{sample}_absrel.json"
    shell:
        '''
        hyphy absrel --alignment {input.alignment} --tree {input.tree} --output {output} --srv Yes --syn-rates 3 --multiple-hits Double+Triple
        '''