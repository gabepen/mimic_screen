import argparse
import os
from tqdm import tqdm 
import zipfile 
import shutil
import subprocess


def collect_ortholog_seqs(workdir, query_sequence):
    
    # create output folder 
    os.makedirs(workdir + '/msa_files', exist_ok=True)
    
    # parse matching orthologs.tsv storing accessions in a list
    ortho_accession_tsv = f"{workdir}/orthologs/{query_sequence}_orthologs.tsv"
    ortho_accessions = []
    with open(ortho_accession_tsv, 'r') as f:
        lines = f.readlines()
        for l in lines:
            ortho_accessions.append(l.split()[0])
    
    # means accession was not found in query proteome
    if len (ortho_accessions) == 0:
        return None
    
    # download ortholog sequences from NCBI datasets as one fasta file 
    print(f"downloading {len(ortho_accessions)} ortholog sequences of {query_sequence} from NCBI datasets...")
    output_path = f"{workdir}/msa_files/{query_sequence}_orthologs_dataset.zip"
    download_command = f"datasets download gene accession {' '.join(ortho_accessions)} --include gene --filename {output_path}"
    subprocess.run(download_command, shell=True)

    # extract and return path to protein fasta 
    zip_path = os.path.join(output_path)
    extract_dir = os.path.splitext(zip_path)[0]
    multiseq_fasta = f"{workdir}/msa_files/{query_sequence}"
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extract('ncbi_dataset/data/gene.fna',path=multiseq_fasta)
        
    # move protein.faa up two directories
    shutil.move(os.path.join(multiseq_fasta, "ncbi_dataset/data/gene.fna"), multiseq_fasta)
    
    # delete the empty ncbi_dataset directory
    shutil.rmtree(os.path.join(multiseq_fasta, "ncbi_dataset"))
    
    return multiseq_fasta
            
def collect_ortholog_accesssions(query_sequence, query_id, workdir):

    ''' Parses the rbh_results directory generated by mmseq2_RBH calls and 
        collects the rbh for the query sequences accession number from each organism
    '''
    
    os.makedirs(workdir + '/orthologs', exist_ok=True)
    
    # Set the output file path
    o_file = f"{workdir}/orthologs/{query_sequence}_orthologs.tsv"
    
    # for tracking duplicates 
    collected_accessions = set()
    
    # Open the output file in append mode
    with open(o_file, 'w+') as o:

        for file in os.listdir(workdir + '/rbh_results'):
            
            # match query organisms id
            if file.startswith(query_id):
                
                # Open the rbh file for the query sequence
                with open(os.path.join(workdir, 'rbh_results', file), 'r') as f:
                    
                    # Parse the file line by line
                    for line in f:
                        
                        # Split the line into fields
                        fields = line.strip().split()
                        
                        # Write out rbh hits to the query accession number
                        if fields[0] == query_sequence and fields[1] not in collected_accessions:
                            collected_accessions.add(fields[1])
                            o.write('\t'.join(fields[1:]) + '\n')
                    
def main():
    
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="")
    parser.add_argument("-i", "--query_id", help="ID of the query microbe")
    parser.add_argument("-s", "--query_sequence", help="Specific query sequence from the proteome")
    parser.add_argument("-w", "--workdir", help="Path to the working directory")
    parser.add_argument("-t", "--threads", type=int, help="Number of threads for mmseqs to use")
    args = parser.parse_args()
    
    
    collect_ortholog_accesssions(args.query_sequence, args.query_id, args.workdir)

    # collect ortholog sequences into a single fasta file 
    ortholog_seq_fasta = collect_ortholog_seqs(args.workdir, args.query_sequence)
    

if __name__ == "__main__":
    main()