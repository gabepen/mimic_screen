import os
import zipfile
import subprocess
import shutil
import argparse
from loguru import logger
import filter_rbh_results

def mmseq2_RBH(query_proteome, query_id, workdir, genome_archive, genomes_selected, threads):
    
    # create results directory 
    os.makedirs(workdir + '/rbh_results', exist_ok=True)
            
    # Establish paths for genome archive extraction
    zip_path = os.path.join(genome_archive)
    extract_dir = os.path.splitext(zip_path)[0]
    
    # check that the genome is in the selected list
    taxid = extract_dir.split('/')[-1].split('_')[0]
    if taxid not in genomes_selected:
        return
    
    # Extract the contents of the zip file to a directory with the same name
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    
    # select target proteome fasta from extracted files 
    data_dir = os.path.join(extract_dir, 'ncbi_dataset', 'data')
    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
    subdir = subdirs[0]
    genome_accession = subdir
    t_fasta = os.path.join(data_dir, subdir, 'protein.faa')
    
    
    # Establish the path for the RBH output file
    rbh_output_path = f"{workdir}/rbh_results/{taxid}_dataset.tsv"
    rbh_filtered_output_path = f"{workdir}/rbh_results/{taxid}_dataset_filtered.tsv"
    
    # Set output format 
    output_fields = '"query,target,fident,alnlen,mismatch,tlen,qlen,qcov,tcov,evalue"'
    
    # Check if the rbh results already exist
    '''
    if os.path.exists(rbh_output_path):
        # Clean up the extracted files
        shutil.rmtree(extract_dir)
        return
    '''
    
    # Run mmseqs easy-rbh to identify orthologs
    mmseqs_command = f"mmseqs easy-rbh {query_proteome} {t_fasta} {rbh_output_path} {workdir}/tmp_{taxid} --threads {threads} --format-output {output_fields}" #> /dev/null"
    subprocess.run(mmseqs_command, shell=True)
    
    # log mmseq genome usage 
    logger.info(f"{taxid} | {genome_accession}")
    
    # filtering the results
    filtered_line_counts = filter_rbh_results.filter_rbh_results(rbh_output_path, rbh_filtered_output_path)
    logger.info(f"evalue filtered: {filtered_line_counts[0]} | coverage filtered: {filtered_line_counts[1]}")
    
    # Clean up the extracted files
    shutil.rmtree(extract_dir)
    shutil.rmtree(f"{workdir}/tmp_{taxid}")
            

def main():
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="RBH blastp analysis for identifying orthologs")
    parser.add_argument("-p", "--query_proteome", help="Path to the query proteome file")
    parser.add_argument("-i", "--query_id", help="ID of the query microbe")
    parser.add_argument("-s", "--genomes_selected", help="Path to file generated by download_genomes")
    parser.add_argument("-w", "--workdir", default="work", help="Path to the working directory")
    parser.add_argument("-t", "--threads", type=int, help="Number of threads for mmseqs to use")
    parser.add_argument("-g", "--genome_archive", help="path of the genome archive file")
    parser.add_argument("-l", "--log", default="logs/", help="log file name")
    args = parser.parse_args()

    # initialize logging 
    logger.remove()  # Remove default handler
    log_file = args.log + f"mmseq_rbh.log"
    logger.add(log_file, rotation="500 MB") # Add a log file handler
    
    # Load the genomes_selected file into a list
    genomes_selected = []
    with open(args.genomes_selected, 'r') as file:
        for line in file:
            genomes_selected.append(line.strip())
            
    mmseq2_RBH(args.query_proteome, args.query_id, args.workdir, args.genome_archive, genomes_selected, args.threads)
    
if __name__ == "__main__":
    main()